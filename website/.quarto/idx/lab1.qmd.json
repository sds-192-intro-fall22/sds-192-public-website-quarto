{"title":"Lab 1: Understanding Datasets","markdown":{"yaml":{"title":"Lab 1: Understanding Datasets","author":"Lindsay Poirier","format":"html","editor":"visual"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nThis lab is all about learning to understand the context and parts of a dataset. In the process of practicing these skills, you will also learn about how to problem solve when coding in `R`.\n\n### Learning Goals\n\n-   Read a data dictionary\n\n-   Reference data documentation\n\n-   Identify unique observations in a dataset\n\n-   Understand different variable types and the kinds of operations you would preform on them\n\n## Review of Key Terms\n\nIn this course, we will be working entirely with *rectangular datasets* - i.e. datasets in which all rows are the same length, and all columns are the same length.\n\n### How do we refer to the parts of a rectangular dataset?\n\n**We refer to each row in a dataset as an *observation* and each column in a dataset as a *variable*.** This is because rows refer to something that we see in the world, and columns describe that thing we are seeing. Imagine we have a table like this below.\n\n| Name  | Age | Birth Month | Time on Phone |\n|-------|-----|-------------|---------------|\n| Sally | 23  | 3           | 42            |\n| Julie | 40  | 2           | 98            |\n| Mark  | 14  | 8           | 120           |\n\nEach row is an observation - in this case a person - and each column is a variable describing something about a person.\n\n### What are the technical components of a rectangular dataset in `R`?\n\nYou may recall that in `R`, *vectors* are a one-dimensional set of values that are all of the same type. A vector can be of type integer (non-decimal numbers), double (decimal numbers), characters (letters and symbols), logical (TRUE/FALSE), for example. Because all of the values in a vector are of the same type, we can perform certain operations across all of the values stored in a vector (e.g. adding all the numbers in a vector up or pasting all of the characters in a vector together). Note how we create a vector of numeric values below, check its type, and then perform an operation on it:\n\n```{r}\n# Note how we create a vector by listing the values in `c()`\ntime_on_phone <- c(42, 98, 120)\n\n# We check the data type like this. \ntypeof(time_on_phone)\n\n# We sum the values in the vector like this. \nsum(time_on_phone)\n```\n\nWhen we create or import rectangular datasets into `R`, they will be stored as a *data frame*. In a data frame, each column is technically a vector, and the name of that vector corresponds to the column's name. So in the table we created above, the Name column is a character vector of names, the Age column is a numeric vector of ages.\n\n::: callout-important\nI use the letters `df` as a placeholder to refer to an arbitrary data frame in `R`. Any time that I refer to `df` in a lab, know that you can swap out `df` with any data frame in your environment.\n:::\n\nRectangular Datasets\n\n:   datasets in which all rows are the same length, and all columns are the same length\n\nObservations\n\n:   rows in a dataset\n\nVariables\n\n:   columns in a dataset; describe something about an observation\n\nVector\n\n:   one-dimensional set of values that are all of the same type\n\nData Frame\n\n:   a list of vectors of equal lengths; typically organizes data into a two-dimensional table composed of columns (the vectors) and rows\n\nUnique Key\n\n:   variable (column) in the dataset that can be used to uniquely identify each row\n\n## Scorecard Dataset\n\nIn his 2013 State of the Union Address, President Barack Obama announced his plans to create a \"college scorecard\" that would allow prospective students and parents to compare schools in terms of cost, offerings, diversity, completion rates, and post-graduate earnings. This data was first published in 2015 and since has undergone several improvements and revisions.\n\nThe College Scorecard dataset is *massive*. In fact, I thought long and hard about whether this was really the first dataset I wanted to introduce to you in a lab. It includes information about over \\_\\_\\_\\_\\_ institutions in the U.S., and has more than 3000 columns documenting information about those institutions. I chose this dataset for this lab because, if you can learn to read this data dictionary, you will be leaps and bounds ahead of the game in learning to read other data dictionaries. (It's also just a super cool dataset, and hint, hint: you will get a chance to dive into it in much more detail in a few weeks). While the full data is available online, we are only going to work with a small subset of the data today.\n\n## Setting Up Your Environment\n\n1.  Install the RScorecard package by entering the following into your Console: `install.packages(\"rscorecard\")`\n\n2.  Create a Scorecard API Key at [this link](https://api.data.gov/signup/). Shortly after you fill out the form, you will be emailed a key. Copy that key into code chunk below. Be sure to wrap the key in quotation marks.\n\n3.  Download the Scorecard Data Dictionary and Technical Documentation for Institution-Level Data Files [here](https://collegescorecard.ed.gov/data/documentation/).\n\n4.  Run the code below to the import 2018 Scorecard data for Massachusetts into `R`. Call me or one of the data assistants over if you get an error.\n\n```{r import}\nlibrary(tidyverse)\nlibrary(rscorecard)\nsc_key(Sys.getenv(\"SCORECARD_KEY\"))\n\nscorecard <- sc_init() %>%\n  sc_year(2018) %>%                 #Note how we are looking at only 2021 data here!\n  sc_filter(stabbr == \"MA\") %>%     #Note how we are looking at only Massachusetts data here!\n  sc_select(unitid, instnm, city, highdeg, control, adm_rate, costt4_a, costt4_p, pcip27, pctfloan, admcon7, wdraw_orig_yr2_rt, cdr3, ugds_white, ugds_black) %>%\n  sc_get()\n```\n\n## Glimpsing the Data\n\nWhen working with very large datasets, we need tools to help us get a sense of the dataset without having to load the entire data frame. For instance, we can view the first 6 rows of the dataset by calling `head()`.\n\n```{r}\nscorecard %>% head()\n```\n\n`str()` provides a great deal of information about the observations in the data frame, including the number of variables, the number of observations, the column names, their data types, and a list of observations.\n\n```{r}\nscorecard %>% str()\n```\n\nYou can also click on the name of your data frame in your Environment panel in RStudio, and it will open a new tab in RStudio that displays the data in a tabular format. Try clicking on `scorecard` in your Environment panel.\n\n::: callout-tip\nThis is the same as calling `df %>% View()` in your Console.\n:::\n\nNote the column names for this dataframe, and the kinds of values that appear in those columns. Some of them (like `city` and `year`) might make sense to you immediately. Others (like `pcip27` and `highdeg`) might be much more confusing. To figure out what we are looking out, we are going to need to refer to the dataset's data dictionary.\n\n## Getting to Know this Dataset\n\n### Observations (Rows)\n\nIn starting our data analysis, we need to have a good sense of what each observation in our dataset refers to - or its *observational unit*. Think of it this way. If you were to count the number rows in your dataset, what would that number refer to? A *unique key* is a variable (or set of variables) that uniquely identifies an observation in the dataset. Think of a unique key as a unique way to identify a row and all of the values in it. There should never be more than one row in the dataset with the same unique key. A unique key tells us what each row in the dataset refers to.\n\n::: callout-important\n## Exercise 1\n\nSee if you can identify a unique key for this dataset. Write some lines of code to determine whether the column you've identified can act as unique key for the data. Hint: You need to check whether the values in the column ever repeat.\n:::\n\n```{r}\n# Write code to check if values in column are all unique here.\n```\n\n::: callout-tip\nNote that NAME is typically not an appropriate variable to use as a unique key. Let me provide an example to demonstrate this. When I worked for BetaNYC, I was trying to build a map of vacant storefronts in NYC by mapping all commercially zoned properties in the city, and then filtering out those properties where a business was licensed or permitted. This way the map would only include properties where there wasn\\'t a business operating. One set of businesses I was filtering out was restaurants. The only dataset that the city had made publicly available for restaurant permits was broken. It was operating on an automated process to update whenever there was a change in the permit; however, whenever a permit was updated, rather than updating the appropriate fields in the existing dataset, it was creating a new row in the dataset that only included the permit holder (the restaurant name), the permit type, and the updated fields. Notably the unique permit ID was not being included in this new row. We pointed this issue out to city officials, but fixing something like this can be slow and time-consuming, so in the meantime, we looked into whether we could clean the data ourselves by aggregating the rows that referred to the same restaurant. However, without the permit ID it was impossible to uniquely identify the restaurants in the dataset. Sure, we had the restaurant name, but do you know how many Wendy\\'s there are in NYC?\n:::\n\nAnytime we count something in the world, we are not only engaging in a process of tabulation; we are also engaging in a process of defining. If I count the number of students in a class, I first have to define what counts as a student. If someone is auditing the class, do they count? If I, as the instructor, am learning from my students, do I count myself as a student? As I make decisions about how I\\'m going to define \"student,\" those decisions impact the numbers that I produce. When I change my definition of \"student,\" how I go about tabulating students also changes. Thus, as we prepare to count observations in a dataset, it is important to know how those observations are defined.\n\n::: callout-important\n## Exercise 2\n\nAt this point, you've probably figured out that each row in this dataset is a higher education institution. ...but there are many different ways that we can define higher education institutions, and that will impact what gets included and excluded in our data. Referencing the Technical Documentation, locate a definition for the unit of observation in this dataset. What institutions are included, and what institutions are excluded? Summarize a definition below.\n:::\n\n> Summarize definition here.\n\n### Variables (Columns)\n\nOpen the data dictionary you downloaded in an earlier step. It will open as an Excel file. Click on the tab labeled \"Institution_Data_Dictionary\". There are thousands of variables in this dataset, falling into the broader categories of school, completion, admissions, cost, etc. Note how the file is organized, and specifically draw your attention to:\n\n-   Column 1 (NAME OF DATA ELEMENT): This is a long description of the variable and gives you clues as to what is represented in it.\n\n-   Column 6 (VARIABLE NAME): This is the column name for the variable. This is how you will reference the variable in `R`.\n\n-   Column 7 (VALUE): These are the possible values for that variable. Note that for many categorical variables, the values are numbers. We are going to have to associate the numbers with their corresponding labels.\n\n-   Column 8 (LABEL): These are the labels associated with the values recorded for the variable.\n\n-   Column 11 (NOTES): This provides notes about the variable, including whether it is currently in use and what missing values indicate.\n\n::: callout-important\n## Exercise 3\n\nIdentify one nominal variable, one ordinal variable, one discrete variable, and one continuous variable.\n:::\n\n### Values (Cells)\n\n::: callout-important\n## Exercise 4\n\nRecode/factor ordinal variable\n:::\n\n::: callout-important\n## Exercise 5\n\nCut numeric variable into buckets and label them\n:::\n\n### Missing Values\n\n::: callout-important\n## Exercise 6\n\nDetermine the number of missing values in \\_\\_.\n:::\n\n::: callout-caution\n## Ethical Considerations\n\nReferencing the College Scorecard data documentation, see if you can determine which students are included in calculations of earnings and debt. How might the data's coverage bias the values that get reported? What might be the social consequences of these biases? Share your ideas on our \\`sds-192-discussions\\` Slack channel.\n:::\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"lab1.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"0.9.342","theme":"flatly","toc_float":{"collapsed":true,"smooth_scroll":false},"highlight":"tango","lib_dir":"libs","title":"Lab 1: Understanding Datasets","author":"Lindsay Poirier","editor":"visual"},"extensions":{"book":{"multiFile":true}}}}}